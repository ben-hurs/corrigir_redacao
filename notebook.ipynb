{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70e52395",
   "metadata": {},
   "source": [
    "## Explorando o modelo pré-treinado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f6221b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f2aeb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "312bc5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projetos\\corrigir_redacao\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\projetos\\corrigir_redacao\\venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\projetos\\corrigir_redacao\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classificador = pipeline('zero-shot-classification', model = 'Mel-Iza0/zero-shot', tokenizer = 'Mel-Iza0/zero-shot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df8c0a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Com o início da era digital, a capacidade de transmissão de informações cresceu apressuradamente, o que facilitou o contato com diversos assuntos, dentre eles a educação sexual . Entretanto, surgiram paralelamente algumas questões, das quais se destacam a preocupação com o momento adequado do ingresso do tema a vida do estudante, assim como de maneira antagônica, o aumento de casos de DST´S\\\\xa0\\\\xa0e gravidez indesejada nesse período, a qual leva a um maior questionamento sobre o começo desta pauta., A falta de comunicação sobre a sexualidade entre jovens no Brasil acarreta muitas das vezes\\\\xa0na inserção desses em um meio repleto de dúvidas, gerando a ocorrência de doenças sexualmente transmissíveis e de gravidez precoce. Com base nisso, muitos adolescentes buscam compreender melhor essas questões na internet, local onde se podem encontrar notícias falsas ou inadequadas para seu desenvolvimento, impedindo assim a correta compreensão do assunto, assim como a responsabilidade imposta por ele., Por outro lado, o diálogo em relação à sexualidade e seus tópicos é um tabu para pais e professores, que se sentem desorientados sobre a devida hora e os devidos critérios a serem tratados com os filhos e alunos, dificultando com que esses esclareçam suas dúvidas e entenda de maneira correta, o que levaria a conscientização da seriedade dessa discussão., Em virtude do que foi mencionado, as indagações a respeito divide vrias opiniões e reflexões acima do que deve ser feito. É de extrema importância o Ministério da Educação, em parceria com o Ministério da Cidadania, implantar a educação sexual na matriz curricular estudantil dos jovens, através de aulas elaboradas e destinadas ao esclarecimento de perguntas, assim como palestras e programas com a intenção de propagar o conteúdo aos estudantes, contando com o suporte dos pais, funcionários e encarregados da rede de ensino no país, para que seja realizado constantemente.',\n",
       " 'labels': ['0', '8', '9', '2', '10', '7', '5', '3', '6', '4', '1'],\n",
       " 'scores': [0.11875257641077042,\n",
       "  0.09610152244567871,\n",
       "  0.09609583765268326,\n",
       "  0.09293803572654724,\n",
       "  0.09243641048669815,\n",
       "  0.08996480703353882,\n",
       "  0.0899394154548645,\n",
       "  0.0848926454782486,\n",
       "  0.08176566660404205,\n",
       "  0.08102332055568695,\n",
       "  0.07608979195356369]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto = 'Com o início da era digital, a capacidade de transmissão de informações cresceu apressuradamente, o que facilitou o contato com diversos assuntos, dentre eles a educação sexual . Entretanto, surgiram paralelamente algumas questões, das quais se destacam a preocupação com o momento adequado do ingresso do tema a vida do estudante, assim como de maneira antagônica, o aumento de casos de DST´S\\\\xa0\\\\xa0e gravidez indesejada nesse período, a qual leva a um maior questionamento sobre o começo desta pauta., A falta de comunicação sobre a sexualidade entre jovens no Brasil acarreta muitas das vezes\\\\xa0na inserção desses em um meio repleto de dúvidas, gerando a ocorrência de doenças sexualmente transmissíveis e de gravidez precoce. Com base nisso, muitos adolescentes buscam compreender melhor essas questões na internet, local onde se podem encontrar notícias falsas ou inadequadas para seu desenvolvimento, impedindo assim a correta compreensão do assunto, assim como a responsabilidade imposta por ele., Por outro lado, o diálogo em relação à sexualidade e seus tópicos é um tabu para pais e professores, que se sentem desorientados sobre a devida hora e os devidos critérios a serem tratados com os filhos e alunos, dificultando com que esses esclareçam suas dúvidas e entenda de maneira correta, o que levaria a conscientização da seriedade dessa discussão., Em virtude do que foi mencionado, as indagações a respeito divide vrias opiniões e reflexões acima do que deve ser feito. É de extrema importância o Ministério da Educação, em parceria com o Ministério da Cidadania, implantar a educação sexual na matriz curricular estudantil dos jovens, através de aulas elaboradas e destinadas ao esclarecimento de perguntas, assim como palestras e programas com a intenção de propagar o conteúdo aos estudantes, contando com o suporte dos pais, funcionários e encarregados da rede de ensino no país, para que seja realizado constantemente.'\n",
    "classificador(texto , candidate_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb38c6a",
   "metadata": {},
   "source": [
    "## Realizando deploy com gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fdcfaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5156606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def mostrar_resultado(texto):\n",
    "    return classificador(texto , candidate_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])['labels'][0]\n",
    "\n",
    "\n",
    "app = gr.Interface(\n",
    "    fn = mostrar_resultado,\n",
    "    inputs = ['text'],\n",
    "    outputs = ['text']\n",
    ")\n",
    "\n",
    "app.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c5924e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://37068263094ac2675a.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://37068263094ac2675a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = gr.Interface(\n",
    "    fn = mostrar_resultado,\n",
    "    inputs = ['text'],\n",
    "    outputs = ['text']\n",
    ")\n",
    "\n",
    "app.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1e5ea8",
   "metadata": {},
   "source": [
    "## Preparando a base de textos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e17aee",
   "metadata": {},
   "source": [
    "Como nossa tarefa é muito específica, o modelo zero-shot não vai lidar muito bem com a situação. O que podemos fazer é explorar uma base de dados que contêm redações e suas respectivas notas e criar um modelo que fará a atribuição da nota com base no texto.\n",
    "\n",
    "Tarefas de NLP são muito complexas e criar um modelo do zero a partir de poucos dados se torna ineficiente. O que vamos fazer é utilizar um modelo pré-treinado a partir de um corpus textual em português e transferir o conhecimento desse modelo para um novo modelo que vai se especializar na tarefa de atribuir notas a redações. Essa tarefa é conhecida como **Transfer Learning** ou **transferência de aprendizado**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa5d240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc8d4739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['essay', 'score'],\n",
       "        num_rows: 4570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dados_redacoes = load_dataset('csv', data_files = 'redacoes.csv')\n",
    "\n",
    "dados_redacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8ba2201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'essay': Value('string'), 'score': Value('int64')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_redacoes['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ebfab7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A convivência com o ensino em uma escola pública , nos mostra \\\\xa0como a reforma do ensino médio é necessária, com o ensino precário, escolas quase desabando, falta de educadores,a formação de estudantes fica a \\\\xa0cada dia mais difícil., Atualmente o índice de jovens que procuram uma educação de qualidade é maior do que em todos os séculos , temos em vista que todos procuram a melhoria, tanto na estrutura da instituição como no ensino, muitos sonham em ser: médicos, professores,advogados, contadores, e assim sucessivamente., A solução seria a constatação de uma lei em prol dos estudantes, precisamos ser ouvidos, a voz dos jovens é a voz do futuro, queremos o ensino superior, queremos oportunidades em escolas públicas, escolas bem estruturada e profissionais competentes., Creio \\\\xa0que a reforma deveria ocorrer, pois o intuito é a melhoria (Que tipo de melhoria?,\\\\xa0assim todos os jovens teriam a oportunidade de serem profissionais de sucesso. O incentivo ( aos jovens é o que torna o país como sendo uma pátria de governantes justos e conhecedores de seus deveres .'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_redacoes['train']['essay'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfc9b31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_redacoes['train']['score'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb3c8e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A convivência com o ensino em uma escola públi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O Brasil possui aproximadamente 425 mil polici...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O esporte é muito importante, as Olimpíadas, u...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O conceito de \"banalidade do mal\" da filósofa ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Um dos assuntos que mais geram discussões atua...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4565</th>\n",
       "      <td>Com o início da era digital, a capacidade de t...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4566</th>\n",
       "      <td>O feminicídio é o assassinato de uma mulher, a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4567</th>\n",
       "      <td>Foram vrias as conquistas que as mulheres bras...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4568</th>\n",
       "      <td>Segundo o psicoterapeuta Ivan Carpelatto: “a v...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4569</th>\n",
       "      <td>Promulgada em 1988, a Constituição Federal a e...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4570 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  essay  score\n",
       "0     A convivência com o ensino em uma escola públi...      4\n",
       "1     O Brasil possui aproximadamente 425 mil polici...      5\n",
       "2     O esporte é muito importante, as Olimpíadas, u...      8\n",
       "3     O conceito de \"banalidade do mal\" da filósofa ...      8\n",
       "4     Um dos assuntos que mais geram discussões atua...      5\n",
       "...                                                 ...    ...\n",
       "4565  Com o início da era digital, a capacidade de t...      6\n",
       "4566  O feminicídio é o assassinato de uma mulher, a...      4\n",
       "4567  Foram vrias as conquistas que as mulheres bras...      5\n",
       "4568  Segundo o psicoterapeuta Ivan Carpelatto: “a v...      9\n",
       "4569  Promulgada em 1988, a Constituição Federal a e...      7\n",
       "\n",
       "[4570 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_redacoes['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6316c294",
   "metadata": {},
   "source": [
    "### Separando os dados entre treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "def5717d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['essay', 'score'],\n",
       "        num_rows: 3656\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['essay', 'score'],\n",
       "        num_rows: 914\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino_teste = dados_redacoes['train'].train_test_split(test_size = 0.2, shuffle = False)\n",
    "treino_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fa971f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    treino: Dataset({\n",
       "        features: ['essay', 'score'],\n",
       "        num_rows: 3656\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['essay', 'score'],\n",
       "        num_rows: 914\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "dados_redacoes = DatasetDict({\n",
    "    'treino': treino_teste['train'],\n",
    "    'test': treino_teste['test']\n",
    "})\n",
    "\n",
    "dados_redacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11aa127f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    treino: Dataset({\n",
       "        features: ['essay', 'score'],\n",
       "        num_rows: 3656\n",
       "    })\n",
       "    teste: Dataset({\n",
       "        features: ['essay', 'score'],\n",
       "        num_rows: 914\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "dados_redacoes = DatasetDict({\n",
    "    'treino': treino_teste['train'],\n",
    "    'teste': treino_teste['test']\n",
    "})\n",
    "\n",
    "dados_redacoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91152aa6",
   "metadata": {},
   "source": [
    "### Tokenizando dados textuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35bf56e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'con', '##viv', '##ência', 'com', 'o', 'ensino', 'em', 'uma', 'escola', 'pública', ',', 'nos', 'mostra', '\\\\', 'xa', '##0', '##com', '##o', 'a', 'reforma', 'do', 'ensino', 'médio', 'é', 'ne', '##ces', '##s', '##ária', ',', 'com', 'o', 'ensino', 'pre', '##c', '##ário', ',', 'escolas', 'quase', 'desa', '##band', '##o', ',', 'falta', 'de', 'edu', '##cado', '##res', ',', 'a', 'formação', 'de', 'estudantes', 'fica', 'a', '\\\\', 'xa', '##0', '##cada', 'dia', 'mais', 'difícil', '.', ',', 'Atualmente', 'o', 'índice', 'de', 'jovens', 'que', 'procura', '##m', 'uma', 'educação', 'de', 'qualidade', 'é', 'maior', 'do', 'que', 'em', 'todos', 'os', 'séculos', ',', 'tem', '##os', 'em', 'vista', 'que', 'todos', 'procura', '##m', 'a', 'melhor', '##ia', ',', 'tanto', 'na', 'estrutura', 'da', 'instituição', 'como', 'no', 'ensino', ',', 'muitos', 'son', '##ham', 'em', 'ser', ':', 'médicos', ',', 'professore', '##s', ',', 'ad', '##vog', '##ados', ',', 'conta', '##dores', ',', 'e', 'assim', 'su', '##ces', '##siva', '##mente', '.', ',', 'A', 'sol', '##ução', 'seria', 'a', 'consta', '##tação', 'de', 'uma', 'lei', 'em', 'pro', '##l', 'dos', 'estudantes', ',', 'precisa', '##mos', 'ser', 'ou', '##vidos', ',', 'a', 'voz', 'dos', 'jovens', 'é', 'a', 'voz', 'do', 'futuro', ',', 'quer', '##emos', 'o', 'ensino', 'superior', ',', 'quer', '##emos', 'oportunidades', 'em', 'escolas', 'públicas', ',', 'escolas', 'bem', 'estrutura', '##da', 'e', 'profissionais', 'compete', '##ntes', '.', ',', 'C', '##rei', '##o', '\\\\', 'xa', '##0', '##que', 'a', 'reforma', 'deveria', 'ocorre', '##r', ',', 'pois', 'o', 'int', '##uito', 'é', 'a', 'melhor', '##ia', '(', 'Que', 'tipo', 'de', 'melhor', '##ia', '?', ',', '\\\\', 'xa', '##0', '##ass', '##im', 'todos', 'os', 'jovens', 'teria', '##m', 'a', 'oportunidad', '##e', 'de', 'serem', 'profissionais', 'de', 'sucesso', '.', 'O', 'in', '##cent', '##ivo', '(', 'aos', 'jovens', 'é', 'o', 'que', 'torna', 'o', 'país', 'como', 'sendo', 'uma', 'p', '##át', '##ria', 'de', 'govern', '##antes', 'justo', '##s', 'e', 'con', '##he', '##cedo', '##res', 'de', 'seus', 'deve', '##res', '.']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint_modelo = 'Geotrend/distilbert-base-pt-cased'\n",
    "\n",
    "tokenizador = AutoTokenizer.from_pretrained(checkpoint_modelo)\n",
    "texto = dados_redacoes['treino']['essay'][0]\n",
    "tokens = tokenizador.tokenize(texto)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da46b7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 270, 24522, 2475, 303, 91, 13849, 348, 469, 5148, 5155, 25, 1125, 4201, 73, 5308, 759, 5563, 231, 77, 8008, 246, 13849, 19640, 144, 539, 2597, 206, 4354, 25, 303, 91, 13849, 1480, 415, 2854, 25, 16687, 8774, 3151, 4948, 231, 25, 5988, 203, 5725, 8294, 920, 25, 77, 11569, 203, 22157, 13510, 77, 73, 5308, 759, 6073, 608, 578, 7859, 27, 25, 12242, 91, 20373, 203, 18423, 220, 21237, 244, 469, 17937, 203, 16944, 144, 2695, 246, 220, 348, 1692, 463, 16426, 25, 1802, 383, 348, 3416, 220, 1692, 21237, 244, 77, 5915, 359, 25, 1813, 230, 9885, 240, 21600, 314, 286, 13849, 25, 6455, 385, 1948, 348, 510, 39, 17306, 25, 17575, 206, 25, 712, 22852, 2092, 25, 5719, 2669, 25, 81, 4832, 292, 2597, 12125, 576, 27, 25, 46, 2996, 10877, 4245, 77, 10673, 15832, 203, 469, 2900, 348, 955, 258, 441, 22157, 25, 15218, 2041, 510, 465, 17157, 25, 77, 4567, 441, 18423, 144, 77, 4567, 246, 5343, 25, 15894, 16539, 91, 13849, 3121, 25, 15894, 16539, 21388, 348, 16687, 13027, 25, 16687, 4577, 9885, 317, 81, 23395, 9010, 2541, 27, 25, 48, 8439, 231, 73, 5308, 759, 899, 77, 8008, 23312, 14665, 227, 25, 4844, 91, 6857, 24540, 144, 77, 5915, 359, 21, 7080, 1911, 203, 5915, 359, 44, 25, 73, 5308, 759, 23325, 1224, 1692, 463, 18423, 13121, 244, 77, 16843, 211, 203, 14346, 23395, 203, 7505, 27, 60, 205, 6686, 2704, 21, 2255, 18423, 144, 91, 220, 6247, 91, 1425, 314, 2371, 469, 92, 1350, 797, 203, 6579, 6661, 20371, 206, 81, 270, 1168, 24814, 920, 203, 1119, 4635, 920, 27]\n"
     ]
    }
   ],
   "source": [
    "ids = tokenizador.convert_tokens_to_ids(tokens)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13943cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A convivência com o ensino em uma escola pública, nos mostra \\ xa0como a reforma do ensino médio é necessária, com o ensino precário, escolas quase desabando, falta de educadores, a formação de estudantes fica a \\ xa0cada dia mais difícil., Atualmente o índice de jovens que procuram uma educação de qualidade é maior do que em todos os séculos, temos em vista que todos procuram a melhoria, tanto na estrutura da instituição como no ensino, muitos sonham em ser : médicos, professores, advogados, contadores, e assim sucessivamente., A solução seria a constatação de uma lei em prol dos estudantes, precisamos ser ouvidos, a voz dos jovens é a voz do futuro, queremos o ensino superior, queremos oportunidades em escolas públicas, escolas bem estruturada e profissionais competentes., Creio \\ xa0que a reforma deveria ocorrer, pois o intuito é a melhoria ( Que tipo de melhoria?, \\ xa0assim todos os jovens teriam a oportunidade de serem profissionais de sucesso. O incentivo ( aos jovens é o que torna o país como sendo uma pátria de governantes justos e conhecedores de seus deveres.\n"
     ]
    }
   ],
   "source": [
    "texto_decodificado = tokenizador.decode(ids)\n",
    "print(texto_decodificado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "683362a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3990e2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   11,    46,   270, 24522,  2475,   303,    91, 13849,   348,   469,\n",
      "          5148,  5155,    25,  1125,  4201,    73,  5308,   759,  5563,   231,\n",
      "            77,  8008,   246, 13849, 19640,   144,   539,  2597,   206,  4354,\n",
      "            25,   303,    91, 13849,  1480,   415,  2854,    25, 16687,  8774,\n",
      "          3151,  4948,   231,    25,  5988,   203,  5725,  8294,   920,    25,\n",
      "            77, 11569,   203, 22157, 13510,    77,    73,  5308,   759,  6073,\n",
      "           608,   578,  7859,    27,    25, 12242,    91, 20373,   203, 18423,\n",
      "           220, 21237,   244,   469, 17937,   203, 16944,   144,  2695,   246,\n",
      "           220,   348,  1692,   463, 16426,    25,  1802,   383,   348,  3416,\n",
      "           220,  1692, 21237,   244,    77,  5915,   359,    25,  1813,   230,\n",
      "          9885,   240, 21600,   314,   286, 13849,    25,  6455,   385,  1948,\n",
      "           348,   510,    39, 17306,    25, 17575,   206,    25,   712, 22852,\n",
      "          2092,    25,  5719,  2669,    25,    81,  4832,   292,  2597, 12125,\n",
      "           576,    27,    25,    46,  2996, 10877,  4245,    77, 10673, 15832,\n",
      "           203,   469,  2900,   348,   955,   258,   441, 22157,    25, 15218,\n",
      "          2041,   510,   465, 17157,    25,    77,  4567,   441, 18423,   144,\n",
      "            77,  4567,   246,  5343,    25, 15894, 16539,    91, 13849,  3121,\n",
      "            25, 15894, 16539, 21388,   348, 16687, 13027,    25, 16687,  4577,\n",
      "          9885,   317,    81, 23395,  9010,  2541,    27,    25,    48,  8439,\n",
      "           231,    73,  5308,   759,   899,    77,  8008, 23312, 14665,   227,\n",
      "            25,  4844,    91,  6857, 24540,   144,    77,  5915,   359,    21,\n",
      "          7080,  1911,   203,  5915,   359,    44,    25,    73,  5308,   759,\n",
      "         23325,  1224,  1692,   463, 18423, 13121,   244,    77, 16843,   211,\n",
      "           203, 14346, 23395,   203,  7505,    27,    60,   205,  6686,  2704,\n",
      "            21,  2255, 18423,   144,    91,   220,  6247,    91,  1425,   314,\n",
      "          2371,   469,    92,  1350,   797,   203,  6579,  6661, 20371,   206,\n",
      "            81,   270,  1168, 24814,   920,   203,  1119,  4635,   920,    27,\n",
      "            12]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "input_codificado = tokenizador(texto, return_tensors = 'pt')\n",
    "print(input_codificado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bc5c130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3656/3656 [00:02<00:00, 1410.42 examples/s]\n",
      "Map: 100%|██████████| 914/914 [00:00<00:00, 1402.56 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def funcao_tokenizadora(dados_texto):\n",
    "    return tokenizador(dados_texto['essay'], truncation = True)\n",
    "\n",
    "\n",
    "dataset_tokenizado = dados_redacoes.map(funcao_tokenizadora, batched = True, remove_columns = ['essay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5f06f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    treino: Dataset({\n",
       "        features: ['score', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 3656\n",
       "    })\n",
       "    teste: Dataset({\n",
       "        features: ['score', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 914\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokenizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d173294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>[11, 46, 270, 24522, 2475, 303, 91, 13849, 348...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>[11, 60, 1497, 6656, 5124, 9019, 2782, 22218, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>[11, 60, 290, 8465, 144, 3240, 1668, 25, 243, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>[11, 60, 19131, 203, 15, 23380, 19311, 246, 28...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[11, 2567, 441, 17363, 206, 220, 578, 2989, 78...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>5</td>\n",
       "      <td>[11, 46, 5148, 1802, 469, 17870, 7326, 230, 11...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>6</td>\n",
       "      <td>[11, 60, 7234, 1280, 3543, 1802, 91, 2885, 203...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>4</td>\n",
       "      <td>[11, 7855, 325, 4776, 4323, 1559, 14086, 13232...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3654</th>\n",
       "      <td>6</td>\n",
       "      <td>[11, 60, 23602, 235, 326, 23949, 206, 203, 179...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3655</th>\n",
       "      <td>8</td>\n",
       "      <td>[11, 15, 617, 10112, 755, 91, 8987, 1071, 77, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3656 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                                          input_ids  \\\n",
       "0         4  [11, 46, 270, 24522, 2475, 303, 91, 13849, 348...   \n",
       "1         5  [11, 60, 1497, 6656, 5124, 9019, 2782, 22218, ...   \n",
       "2         8  [11, 60, 290, 8465, 144, 3240, 1668, 25, 243, ...   \n",
       "3         8  [11, 60, 19131, 203, 15, 23380, 19311, 246, 28...   \n",
       "4         5  [11, 2567, 441, 17363, 206, 220, 578, 2989, 78...   \n",
       "...     ...                                                ...   \n",
       "3651      5  [11, 46, 5148, 1802, 469, 17870, 7326, 230, 11...   \n",
       "3652      6  [11, 60, 7234, 1280, 3543, 1802, 91, 2885, 203...   \n",
       "3653      4  [11, 7855, 325, 4776, 4323, 1559, 14086, 13232...   \n",
       "3654      6  [11, 60, 23602, 235, 326, 23949, 206, 203, 179...   \n",
       "3655      8  [11, 15, 617, 10112, 755, 91, 8987, 1071, 77, ...   \n",
       "\n",
       "                                         attention_mask  \n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "...                                                 ...  \n",
       "3651  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3652  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3653  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3654  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3655  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "\n",
       "[3656 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokenizado['treino'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aab801ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>[11, 60, 9133, 18342, 2294, 220, 13606, 1295, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>[11, 599, 3088, 1306, 25, 22568, 2284, 2251, 8...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[11, 46, 15182, 20233, 16866, 2969, 14150, 81,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>[11, 60, 10910, 303, 469, 7592, 1828, 21261, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>[11, 1876, 91, 3222, 240, 1774, 9151, 359, 25,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>6</td>\n",
       "      <td>[11, 3444, 91, 5764, 240, 452, 3543, 25, 77, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>4</td>\n",
       "      <td>[11, 60, 4880, 1235, 2011, 3575, 144, 91, 2370...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>5</td>\n",
       "      <td>[11, 24848, 98, 8544, 243, 6634, 206, 220, 243...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>9</td>\n",
       "      <td>[11, 4433, 91, 22999, 22429, 14533, 3507, 304,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>7</td>\n",
       "      <td>[11, 2344, 14232, 8091, 348, 534, 25, 77, 2464...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>914 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     score                                          input_ids  \\\n",
       "0        7  [11, 60, 9133, 18342, 2294, 220, 13606, 1295, ...   \n",
       "1        8  [11, 599, 3088, 1306, 25, 22568, 2284, 2251, 8...   \n",
       "2        4  [11, 46, 15182, 20233, 16866, 2969, 14150, 81,...   \n",
       "3        7  [11, 60, 10910, 303, 469, 7592, 1828, 21261, 1...   \n",
       "4        7  [11, 1876, 91, 3222, 240, 1774, 9151, 359, 25,...   \n",
       "..     ...                                                ...   \n",
       "909      6  [11, 3444, 91, 5764, 240, 452, 3543, 25, 77, 1...   \n",
       "910      4  [11, 60, 4880, 1235, 2011, 3575, 144, 91, 2370...   \n",
       "911      5  [11, 24848, 98, 8544, 243, 6634, 206, 220, 243...   \n",
       "912      9  [11, 4433, 91, 22999, 22429, 14533, 3507, 304,...   \n",
       "913      7  [11, 2344, 14232, 8091, 348, 534, 25, 77, 2464...   \n",
       "\n",
       "                                        attention_mask  \n",
       "0    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "..                                                 ...  \n",
       "909  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "910  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "911  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "912  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "913  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "\n",
       "[914 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokenizado['teste'].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd32491",
   "metadata": {},
   "source": [
    "## Ajustando dados para o modelo\n",
    "\n",
    "### Ajustando a variável alvo\n",
    "\n",
    "Para realizar o treinamento do modelo, a variável alvo precisa estar no formato específico ClassLabel. Vamos realizar essa transformação na base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0dc728f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value('int64')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokenizado['treino'].features['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "459b8dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 8, 6, 10, 7, 1, 9, 3, 0, 2]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import ClassLabel\n",
    "dataset_tokenizado['treino'].unique('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f23d3d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = ClassLabel(names = [str(i) for i in range(11)])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7583149e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3656/3656 [00:00<00:00, 27615.13 examples/s]\n",
      "Map: 100%|██████████| 914/914 [00:00<00:00, 19755.80 examples/s]\n",
      "Casting the dataset: 100%|██████████| 3656/3656 [00:00<00:00, 151076.10 examples/s]\n",
      "Casting the dataset: 100%|██████████| 914/914 [00:00<00:00, 57646.29 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    treino: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'label'],\n",
       "        num_rows: 3656\n",
       "    })\n",
       "    teste: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'label'],\n",
       "        num_rows: 914\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapear_labels(dados):\n",
    "    dados['label'] = scores.str2int(str(dados['score']))\n",
    "    return dados\n",
    "\n",
    "dataset_tokenizado = dataset_tokenizado.map(mapear_labels, remove_columns = 'score')\n",
    "\n",
    "dataset_tokenizado = dataset_tokenizado.cast_column('label', scores)\n",
    "\n",
    "dataset_tokenizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1977ea23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokenizado['treino'].features['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bab842",
   "metadata": {},
   "source": [
    "### Preparando dados de treino e teste\n",
    "\n",
    "Agora que já realizamos todas as transformações nos dados, vamos inicializar o modelo pré-treinado e preparar os dados de treino e validação que serão utilizados no treinamento do novo modelo.\n",
    "\n",
    "Modelo de base para tranferência de aprendizado e tokenização:\n",
    "\n",
    "- https://huggingface.co/Geotrend/distilbert-base-pt-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fdaa05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "d:\\projetos\\corrigir_redacao\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--Geotrend--distilbert-base-pt-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\projetos\\corrigir_redacao\\venv\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "checkpoint_modelo = 'Geotrend/distilbert-base-pt-cased'\n",
    "\n",
    "id2label = {0: '0', 1: '1', 2:'2', 3:'3', 4:'4', 5:'5', 6:'6', 7:'7', 8:'8', 9:'9',10:'10'}\n",
    "label2id = {valor: chave for chave, valor in id2label.items()}\n",
    "\n",
    "modelo = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint_modelo,\n",
    "    num_labels = dataset_tokenizado['treino'].features['label'].num_classes,\n",
    "    id2label = id2label,\n",
    "    label2id = label2id,\n",
    "    from_pt = True\n",
    ")\n",
    "\n",
    "\n",
    "dados_treino = modelo.prepare_tf_dataset(\n",
    "    dataset_tokenizado['treino'],\n",
    "    shuffle = True,\n",
    "    batch_size = 16,\n",
    "    tokenizer = tokenizador\n",
    ")\n",
    "\n",
    "dados_validacao = modelo.prepare_tf_dataset(\n",
    "    dataset_tokenizado['teste'],\n",
    "    shuffle = False,\n",
    "    batch_size = 16,\n",
    "    tokenizer = tokenizador\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff75a4",
   "metadata": {},
   "source": [
    "## Treinando o Modelo\n",
    "\n",
    "Para realizar o treinamento do modelo, vamos criar um otimizador e definir os hiperparâmetros do modelo. A partir daí, podemos realizar o treinamento e a avaliação do modelo a partir da métrica Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b97772f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:From d:\\projetos\\corrigir_redacao\\venv\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "228/228 [==============================] - 2016s 9s/step - loss: 1.9092 - val_loss: 1.7378\n",
      "Epoch 2/2\n",
      "228/228 [==============================] - 2025s 9s/step - loss: 1.6676 - val_loss: 1.6256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x261b84a2ba0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import create_optimizer\n",
    "\n",
    "# hiperparametros\n",
    "batch_size = 16\n",
    "epocas = 2\n",
    "batches_por_epoca = len(dataset_tokenizado['treino']) // batch_size\n",
    "total_passos_treino = int(batches_por_epoca * epocas)\n",
    "taxa_aprendizado = 2e-5\n",
    "\n",
    "otimizador, scheduler = create_optimizer(\n",
    "    init_lr = taxa_aprendizado, num_warmup_steps = 0, num_train_steps = total_passos_treino\n",
    ")\n",
    "\n",
    "modelo.compile(optimizer = otimizador)\n",
    "\n",
    "modelo.fit(dados_treino, validation_data = dados_validacao, epochs= epocas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9beae3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 135s 2s/step - loss: 1.6256\n",
      "Loss: 1.6255755424499512\n"
     ]
    }
   ],
   "source": [
    "resultados_avaliacao = modelo.evaluate(dados_validacao)\n",
    "print(f'Loss: {resultados_avaliacao}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee451ef1",
   "metadata": {},
   "source": [
    "## Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf421334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting joblib\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Installing collected packages: joblib\n",
      "Successfully installed joblib-1.5.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55806279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projetos\\corrigir_redacao\\venv\\Lib\\site-packages\\transformers\\generation\\tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['modelo.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(modelo, \"modelo.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3146b8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9360fb49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66201bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8e72dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
